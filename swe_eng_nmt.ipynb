{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "swe_eng_nmt.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/VeereshElango/translator/blob/master/swe_eng_nmt.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "VJHTvxTvwZpi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47b5177c-e8d4-4c7d-dfae-23385d208e9b"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "# Import TensorFlow >= 1.10 and enable eager execution\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AIVI0eYWwjvA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e141be9-9800-4fb2-8f37-ffc87fe1a325"
      },
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "# Download the file\n",
        "def get_data( url, directory ):\n",
        "  if not os.path.exists(directory):\n",
        "      os.makedirs(directory)\n",
        "      filename = url.split(\"/\")[-1]\n",
        "      with open(directory+filename, \"wb\") as f:\n",
        "        r = requests.get(url)\n",
        "        f.write(r.content)\n",
        "      print(\"File downloaded :\",directory+filename)\n",
        "      extract(directory+filename, directory)\n",
        "  else:\n",
        "    print(\"Data exists\")\n",
        "def extract(path, directory_to_extract_to):\n",
        "  zip_ref = zipfile.ZipFile(path, 'r')\n",
        "  zip_ref.extractall(directory_to_extract_to)\n",
        "  zip_ref.close()\n",
        "get_data(\"http://www.manythings.org/anki/swe-eng.zip\",\"./data/\")\n",
        "path_to_file = \"./data/swe.txt\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QgK96vUIxNZJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "99c41174-cd17-4404-c878-0aa964a1a1dc"
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "with open('./data/swe.txt') as f:\n",
        "  all_lines = f.readlines()\n",
        "  print(\"Total Lines : \",len(all_lines))\n",
        "  print()\n",
        "  print(\"3 Samples\\n\")\n",
        "  for i in random.sample(range(1, len(all_lines)), 3):\n",
        "    print(all_lines[i])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Lines :  17300\n",
            "\n",
            "3 Samples\n",
            "\n",
            "Do I look tired?\tSer jag trött ut?\n",
            "\n",
            "Who's your teacher?\tVem är din lärare?\n",
            "\n",
            "My body isn't as flexible as it used to be.\tMin kropp är inte så smidig som den brukade vara.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3ZUi2vFUxWek",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "    \n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\" \n",
        "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    \n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "    \n",
        "    w = w.rstrip().strip()\n",
        "    \n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w\n",
        "  \n",
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "    lines = open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "    \n",
        "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "    \n",
        "    return word_pairs\n",
        "  \n",
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IQtIyv0R0gT7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
        "# (e.g., 5 -> \"dad\") for each language,\n",
        "class LanguageIndex():\n",
        "  def __init__(self, lang):    \n",
        "    self.lang = lang\n",
        "    self.word2idx = {}\n",
        "    self.idx2word = {}\n",
        "    self.vocab = set()\n",
        "    \n",
        "    self.create_index()\n",
        "    \n",
        "  def create_index(self):\n",
        "    for phrase in self.lang:\n",
        "      #print(phrase)\n",
        "      self.vocab.update(phrase.split(' '))\n",
        "    \n",
        "    self.vocab = sorted(self.vocab)\n",
        "    \n",
        "    self.word2idx['<pad>'] = 0\n",
        "    for index, word in enumerate(self.vocab):\n",
        "      self.word2idx[word] = index + 1\n",
        "    \n",
        "    for word, index in self.word2idx.items():\n",
        "      self.idx2word[index] = word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h2GIYHgW0hRf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_examples = 30000\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0dGrjWYb1QdM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "fe7781c9-e8d3-45ef-98fe-74d3ac0ea278"
      },
      "cell_type": "code",
      "source": [
        "# creating cleaned input, output pairs\n",
        "pairs = create_dataset(path_to_file, num_examples)\n",
        "pairs[:5]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['<start> run ! <end>', '<start> spring ! <end>'],\n",
              " ['<start> who ? <end>', '<start> vem ? <end>'],\n",
              " ['<start> help ! <end>', '<start> hjalp ! <end>'],\n",
              " ['<start> jump ! <end>', '<start> hoppa ! <end>'],\n",
              " ['<start> stop ! <end>', '<start> stanna ! <end>']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "O7u7S1BF1fAD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "310d6ccc-8fda-4124-a51a-d3b54a64bef4"
      },
      "cell_type": "code",
      "source": [
        "# index language using the class defined above    \n",
        "inp_lang = LanguageIndex(sw for en, sw in pairs)\n",
        "targ_lang = LanguageIndex(en for en, sw in pairs)\n",
        "print(\"Swedish Vocab : \", len(inp_lang.vocab))\n",
        "print(\"English Vocab : \", len(targ_lang.vocab))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Swedish Vocab :  6945\n",
            "English Vocab :  4853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MpnF6Wgb2Jjd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Swedish sentences\n",
        "input_tensor = [[inp_lang.word2idx[s] for s in sw.split(' ')] for en, sw in pairs]\n",
        "    \n",
        "# English sentences\n",
        "target_tensor = [[targ_lang.word2idx[s] for s in en.split(' ')] for en, sw in pairs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vSvvOgvG4nx6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9c23f9c9-6b73-4676-924e-2bd81636ee88"
      },
      "cell_type": "code",
      "source": [
        "for i in random.sample(range(1, len(all_lines)), 3):\n",
        "  print(pairs[i][1], input_tensor[i])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> lat inte den har informationen lacka ut . <end> [5, 3449, 2719, 1054, 2371, 2675, 3348, 6556, 3, 4]\n",
            "<start> vem kan utfora det har arbetet ? <end> [5, 6801, 2897, 6569, 1070, 2371, 269, 6, 4]\n",
            "<start> tom bestamde sig for att ringa polisen . <end> [5, 6246, 616, 5194, 1659, 353, 4894, 4623, 3, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tFQ_eMBe5GBH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "568dc6a8-4896-42d9-f408-6e5a75a16333"
      },
      "cell_type": "code",
      "source": [
        "# Calculate max_length of input and output tensor\n",
        "# Here, we'll set those to the longest sentence in the dataset\n",
        "max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n",
        "\n",
        "print(\"Swedish Maximum length :\", max_length_inp)\n",
        "print(\"English Maximum length :\", max_length_tar)\n",
        "    "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Swedish Maximum length : 34\n",
            "English Maximum length : 38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TKVEz1HY6ELr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Padding the input and output tensor to the maximum length\n",
        "input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, \n",
        "                                                                 maxlen=max_length_inp,\n",
        "                                                                 padding='post')\n",
        "    \n",
        "target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, \n",
        "                                                                  maxlen=max_length_tar, \n",
        "                                                                  padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ky0tEsaR6Wk-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a898d6ff-f93b-4a89-d1df-8b800bbfb730"
      },
      "cell_type": "code",
      "source": [
        "for i in random.sample(range(1, len(all_lines)), 3):\n",
        "  print(pairs[i][1])\n",
        "  print(input_tensor[i])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> le inte . <end>\n",
            "[   5 3469 2719    3    4    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0]\n",
            "<start> att ata en klyfta vitlok varje dag , ar det nyttigt for dig ? <end>\n",
            "[   5  353  324 1301 3052 6904 6742  984    2  260 1070 4160 1659 1078\n",
            "    6    4    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0]\n",
            "<start> borde vi inte saga nagonting ? <end>\n",
            "[   5  797 6828 2719 5014 4021    6    4    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tgVa7XSo6YgN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ffd689dc-e78b-417e-a89d-1d4a43afd867"
      },
      "cell_type": "code",
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13840, 13840, 3460, 3460)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "cJIjtze86ubL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5e01b498-23a5-41c7-bff6-b255b8a002cb"
      },
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "print(\"N_BATCH :\",N_BATCH)\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word2idx)\n",
        "vocab_tar_size = len(targ_lang.word2idx)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train))\n",
        "print(dataset)\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "print(dataset)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "print(dataset)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N_BATCH : 216\n",
            "<TensorSliceDataset shapes: ((34,), (38,)), types: (tf.int32, tf.int32)>\n",
            "<ShuffleDataset shapes: ((34,), (38,)), types: (tf.int32, tf.int32)>\n",
            "<BatchDataset shapes: ((64, 34), (64, 38)), types: (tf.int32, tf.int32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y_IrOSJQ611J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gru(units):\n",
        "  # If you have a GPU, we recommend using CuDNNGRU(provides a 3x speedup than GRU)\n",
        "  # the code automatically does that.\n",
        "  if tf.test.is_gpu_available():\n",
        "    return tf.keras.layers.CuDNNGRU(units, \n",
        "                                    return_sequences=True, \n",
        "                                    return_state=True, \n",
        "                                    recurrent_initializer='glorot_uniform')\n",
        "  else:\n",
        "    return tf.keras.layers.GRU(units, \n",
        "                               return_sequences=True, \n",
        "                               return_state=True, \n",
        "                               recurrent_activation='sigmoid', \n",
        "                               recurrent_initializer='glorot_uniform')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S6PpNl1r8WRC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = gru(self.enc_units)\n",
        "        \n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state = hidden)        \n",
        "        return output, state\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LoWc9Oi28nZ0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = gru(self.dec_units)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "        # used for attention\n",
        "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "        \n",
        "    def call(self, x, hidden, enc_output):\n",
        "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "        \n",
        "        # hidden shape == (batch_size, hidden size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        # we are doing this to perform addition to calculate the score\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "        \n",
        "        # score shape == (batch_size, max_length, hidden_size)\n",
        "        score = tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis))\n",
        "        \n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying score to self.V\n",
        "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
        "        \n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * enc_output\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        \n",
        "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        \n",
        "        # passing the concatenated vector to the GRU\n",
        "        output, state = self.gru(x)\n",
        "        \n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        \n",
        "        # output shape == (batch_size * 1, vocab)\n",
        "        x = self.fc(output)\n",
        "        \n",
        "        return x, state, attention_weights\n",
        "        \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.dec_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wPZntKiD8xvV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.AdamOptimizer()\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = 1 - np.equal(real, 0)\n",
        "  loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vzB2VXW-9NZG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d528c240-cb6e-47c1-c082-991642fc0ec2"
      },
      "cell_type": "code",
      "source": [
        "print(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6946 256 1024 64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lnThBBOR895I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UEaI7pS09DAD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1037
        },
        "outputId": "32918f5f-a169-404f-e53d-305e89c9b095"
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    #Every epoch, hidden state is initialized\n",
        "    hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "    #print(dataset)\n",
        "    for (batch, (inp, targ)) in enumerate(dataset):\n",
        "        loss = 0\n",
        "        \n",
        "        #print(\"Batch : \",batch, \" Input : \",inp.shape, \" Target : \", targ.shape)\n",
        "        \n",
        "        with tf.GradientTape() as tape:#what is gradient tape ?\n",
        "            enc_output, enc_hidden = encoder(inp, hidden)\n",
        "            \n",
        "            #print(\"Enc Output :\",enc_output.shape)\n",
        "            #print(\"Enc Hidden :\",enc_hidden.shape)\n",
        "            \n",
        "            \n",
        "            dec_hidden = enc_hidden\n",
        "            \n",
        "            dec_input = tf.expand_dims([targ_lang.word2idx['<start>']] * BATCH_SIZE, 1)       \n",
        "            \n",
        "            # Teacher forcing - feeding the target as the next input\n",
        "            for t in range(1, targ.shape[1]):\n",
        "                # passing enc_output to the decoder\n",
        "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "                \n",
        "                loss += loss_function(targ[:, t], predictions)\n",
        "                \n",
        "                # using teacher forcing\n",
        "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "        \n",
        "        batch_loss = (loss / int(targ.shape[1]))\n",
        "        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        variables = encoder.variables + decoder.variables\n",
        "        \n",
        "        gradients = tape.gradient(loss, variables)\n",
        "        \n",
        "        optimizer.apply_gradients(zip(gradients, variables))\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.numpy()))\n",
        "    # saving (checkpoint) the model every 2 epochs\n",
        "    if (epoch + 1) % 2 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                        total_loss / N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 1.5421\n",
            "Epoch 1 Batch 100 Loss 0.8490\n",
            "Epoch 1 Batch 200 Loss 0.5946\n",
            "Epoch 1 Loss 0.8230\n",
            "Time taken for 1 epoch 216.463449716568 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.5398\n",
            "Epoch 2 Batch 100 Loss 0.5837\n",
            "Epoch 2 Batch 200 Loss 0.4963\n",
            "Epoch 2 Loss 0.5312\n",
            "Time taken for 1 epoch 216.44912385940552 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.3902\n",
            "Epoch 3 Batch 100 Loss 0.4200\n",
            "Epoch 3 Batch 200 Loss 0.3195\n",
            "Epoch 3 Loss 0.3856\n",
            "Time taken for 1 epoch 215.2748908996582 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.2476\n",
            "Epoch 4 Batch 100 Loss 0.2922\n",
            "Epoch 4 Batch 200 Loss 0.3264\n",
            "Epoch 4 Loss 0.2830\n",
            "Time taken for 1 epoch 216.2699179649353 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.1770\n",
            "Epoch 5 Batch 100 Loss 0.2226\n",
            "Epoch 5 Batch 200 Loss 0.2049\n",
            "Epoch 5 Loss 0.2064\n",
            "Time taken for 1 epoch 215.92960929870605 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.1447\n",
            "Epoch 6 Batch 100 Loss 0.1324\n",
            "Epoch 6 Batch 200 Loss 0.1823\n",
            "Epoch 6 Loss 0.1635\n",
            "Time taken for 1 epoch 215.81836652755737 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.1205\n",
            "Epoch 7 Batch 100 Loss 0.1193\n",
            "Epoch 7 Batch 200 Loss 0.1093\n",
            "Epoch 7 Loss 0.1222\n",
            "Time taken for 1 epoch 215.66133904457092 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.0725\n",
            "Epoch 8 Batch 100 Loss 0.0974\n",
            "Epoch 8 Batch 200 Loss 0.0796\n",
            "Epoch 8 Loss 0.0927\n",
            "Time taken for 1 epoch 216.12357091903687 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.0773\n",
            "Epoch 9 Batch 100 Loss 0.0665\n",
            "Epoch 9 Batch 200 Loss 0.0960\n",
            "Epoch 9 Loss 0.0729\n",
            "Time taken for 1 epoch 215.1902894973755 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0600\n",
            "Epoch 10 Batch 100 Loss 0.0637\n",
            "Epoch 10 Batch 200 Loss 0.0643\n",
            "Epoch 10 Loss 0.0668\n",
            "Time taken for 1 epoch 215.98015666007996 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PFd9Y7do-VXq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    \n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    inputs = [inp_lang.word2idx[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    \n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word2idx['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "        \n",
        "        # storing the attention weigths to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang.idx2word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang.idx2word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "        \n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bj2ApT3P7Ej9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "    \n",
        "    fontdict = {'fontsize': 14}\n",
        "    \n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XzWm53UC7WQo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def translate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
        "    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)\n",
        "        \n",
        "    print('Input: {}'.format(sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "    \n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RNx-XGab7Yh6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e9bf6ca-e7fa-4bcd-8cb7-00b42d06a782"
      },
      "cell_type": "code",
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x7fd9f01e2b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "q0iFjLSZ7beF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "f2bae990-8324-4db2-ccfe-6e64a9533e05"
      },
      "cell_type": "code",
      "source": [
        "translate('Ser jag trött ut?', encoder, decoder, inp_lang, targ_lang, max_length_inp, 38)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> ser jag trott ut ? <end>\n",
            "Predicted translation: do i look tired ? <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAJhCAYAAACU+G7DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABITXAAAiQkuAIDE/h8czWZOBVbulAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd9ef6002e8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "7JFFhTja7xQz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "1fed16b3-137d-417f-8025-dd5057d054fe"
      },
      "cell_type": "code",
      "source": [
        "translate('Han älskar fotboll.', encoder, decoder, inp_lang, targ_lang, max_length_inp, 38)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> han alskar fotboll . <end>\n",
            "Predicted translation: he loves soccer . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAAJhCAYAAACQDb7+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd9ef6370f0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "s0Yyz-Nu9ZGk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}